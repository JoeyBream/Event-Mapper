{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get Resident Advisor files, using @dirkjbreeuwer repo. \"resident-advisor-events-scraper\"",
   "id": "a7a0882dca04933d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:04:55.093463Z",
     "start_time": "2025-09-02T17:04:51.503451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- IMPORT ------\n",
    "import os\n",
    "\n",
    "from jedi.inference.references import gitignored_paths\n",
    "from win32comext.mapi.mapitags import pidSecureProfileMin\n",
    "\n",
    "from resident_advisor_events_scraper.event_fetcher import EventFetcher\n",
    "from datetime import datetime, timedelta"
   ],
   "id": "a71ee5939e81fccd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:16:47.107783Z",
     "start_time": "2025-09-02T17:16:22.701898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- OUTPUT ------------\n",
    "os.makedirs(\"upcoming_events\", exist_ok=True)\n",
    "output_file = os.path.join(os.getcwd(), \"upcoming_events\", \"ra_events.csv\")\n",
    "\n",
    "# ---------- PARAMETERS ----------\n",
    "area_code = 13\n",
    "days_ahead = 7\n",
    "start_date = datetime.now().strftime('%Y-%m-%d')\n",
    "end_date = (datetime.now() + timedelta(days=days_ahead)).strftime('%Y-%m-%d')\n",
    "listing_date_gte = f\"{start_date}T00:00:00.000Z\"\n",
    "listing_date_lte = f\"{end_date}T23:59:59.999Z\"\n",
    "\n",
    "# ---------- INITIALISE FETCHER ----------\n",
    "fetcher = EventFetcher(area_code, listing_date_gte, listing_date_lte)\n",
    "\n",
    "# ---------- FETCH EVENTS ----------\n",
    "all_events = fetcher.fetch_all_events()\n",
    "\n",
    "# ---------- SAVE TO CSV ----------\n",
    "fetcher.save_events_to_csv(all_events, output_file)\n",
    "\n",
    "print(f\"Saved {len(all_events)} events to {output_file}\")\n",
    "print(f\"Date of scrape: {start_date}\")\n"
   ],
   "id": "2c7cb4f5cdfa6b04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 261 events to C:\\Users\\ADMIN\\OneDrive\\Documents\\Github\\Event-Mapper\\upcoming_events\\ra_events.csv\n",
      "Date of scrape: 2025-09-02\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T22:35:01.900607Z",
     "start_time": "2025-08-21T22:35:01.877462Z"
    }
   },
   "cell_type": "markdown",
   "source": "Upload file to Supabase table",
   "id": "8a7b7db4fdc9f31a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:05:25.108392Z",
     "start_time": "2025-09-02T17:05:18.936316Z"
    }
   },
   "cell_type": "code",
   "source": "pip install pandas",
   "id": "7dd0c86ec7475a9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:05:34.825426Z",
     "start_time": "2025-09-02T17:05:25.117841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from supabase import create_client, Client\n",
    "\n",
    "load_dotenv()  # This loads the .env file\n",
    "\n",
    "url = os.getenv('SUPABASE_URL')\n",
    "key = os.getenv('SUPABASE_ANON_KEY')\n",
    "supabase: Client = create_client(url, key)"
   ],
   "id": "d82a3d9fbeec7b01",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:18:08.092192Z",
     "start_time": "2025-09-02T17:18:07.881541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# After your scraping code generates the CSV\n",
    "df = pd.read_csv('upcoming_events/ra_events.csv')\n",
    "\n",
    "# Clean the data - replace NaN values\n",
    "df = df.fillna('')  # Replace NaN with empty strings\n",
    "\n",
    "# Optional: Convert any remaining problematic values\n",
    "df = df.replace([np.inf, -np.inf], '')  # Handle infinity values too\n",
    "\n",
    "# Remove duplicates based on URL column\n",
    "original_count = len(df)\n",
    "df = df.drop_duplicates(subset=['Event URL'], keep='first')\n",
    "duplicates_removed = original_count - len(df)\n",
    "\n",
    "print(f\"Original events: {original_count}\")\n",
    "print(f\"Duplicates removed: {duplicates_removed}\")\n",
    "print(f\"After removing duplicates: {len(df)} events\")"
   ],
   "id": "d3b32f2d88239e60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original events: 261\n",
      "Duplicates removed: 9\n",
      "After removing duplicates: 252 events\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:18:12.959608Z",
     "start_time": "2025-09-02T17:18:12.624102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Convert to list of dicts for Supabase\n",
    "events_data = df.to_dict('records')\n",
    "\n",
    "# Insert with upsert to handle duplicates\n",
    "try:\n",
    "    result = supabase.table('resident_advisor').upsert(events_data, on_conflict='Event URL').execute()\n",
    "    print(f\"Uploaded {len(result.data)} events\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading: {e}\")"
   ],
   "id": "4be120c6995ff913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 252 events\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c677e437986c6dfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
